# Code (exact same example)

```python
import torch
import torch.nn as nn
import torch.optim as optim

# Simple model
model = nn.Linear(10, 1)

# Loss function and optimizer
criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

# Dummy dataset
X = torch.randn(100, 10)
y = torch.randn(100, 1)

# Training loop
for epoch in range(5):  # 5 epochs
    for i in range(0, len(X), 16):   # batch size = 16
        inputs = X[i:i+16]
        targets = y[i:i+16]

        # 1. Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, targets)

        # 2. Backward pass
        optimizer.zero_grad()   # clear gradients
        loss.backward()         # compute gradients

        # 3. Update weights
        optimizer.step()        # adjust weights

    print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")
```

---

# Comprehensive, step-by-step explanation

Below I go through every line/step and explain what’s happening under the hood, expected tensor shapes, math, common pitfalls and best practices.

---

## Setup (model, loss, optimizer, data)

* `model = nn.Linear(10, 1)`

  * Creates a linear layer $y = xW^T + b$.
  * `weight` shape: `(out_features, in_features)` → `(1, 10)`.
  * `bias` shape: `(out_features,)` → `(1,)`.
  * Both `weight` and `bias` are `torch.nn.Parameter` with `requires_grad=True` by default (so gradients will be computed for them).

* `criterion = nn.MSELoss()`

  * Mean Squared Error loss.
  * Default `reduction='mean'` → loss = mean of squared errors across **all elements** in the batch.
  * If your outputs are shape `(B, 1)`, loss = (1 / (B\*1)) \* sum\_i (outputs\_i - targets\_i)^2.

* `optimizer = optim.SGD(model.parameters(), lr=0.01)`

  * Stochastic Gradient Descent (no momentum here).
  * On `optimizer.step()`, each parameter `p` is updated in-place as:

    ```
    p.data = p.data - lr * p.grad
    ```

    (conceptually — PyTorch handles details and dtype/device matching).

* `X = torch.randn(100, 10)` and `y = torch.randn(100, 1)`

  * `X` shape: `(100, 10)` — 100 examples, each 10 features.
  * `y` shape: `(100, 1)` — 100 scalar targets.
  * Default dtype: `torch.float32`. Default device: CPU (unless moved).

---

## Outer loop: epochs

```python
for epoch in range(5):  # 5 epochs
```

* One **epoch** = one full pass through the dataset (`X`, `y`).
* We run 5 epochs here. Typically you monitor training/validation loss to decide how many epochs are needed.

---

## Mini-batching

```python
for i in range(0, len(X), 16):   # batch size = 16
    inputs = X[i:i+16]
    targets = y[i:i+16]
```

* Batch size = 16 (except the last batch which may be smaller).

  * For 100 samples and batch 16: `ceil(100/16) = 7` batches per epoch.
  * Batch sizes: `16,16,16,16,16,16,4` (last batch has 4 samples).
* `inputs` shape: `(B, 10)` where `B` is current batch size (16 or 4).
* `targets` shape: `(B, 1)`.

**Why batch?** Performance (vectorized ops), stable gradients, memory constraints. Smaller batches give noisier gradients but can generalize better; larger batches are stabler and faster per step.

---

## 1) Forward pass

```python
outputs = model(inputs)
loss = criterion(outputs, targets)
```

* **`model(inputs)`** performs a linear transformation:

  $$
  \text{outputs} = X W^T + b
  $$

  * With `inputs` shape `(B,10)` and `weight` `(1,10)`, PyTorch computes `(B,10) @ (10,1) → (B,1)` (weight is transposed internally).
  * `outputs` shape: `(B,1)`.

* **`loss = criterion(outputs, targets)`**

  * For MSE with reduction='mean':

    $$
    \text{loss} = \frac{1}{B}\sum_{i=1}^{B} ( \hat{y}_i - y_i )^2
    $$

    (since output dimension is 1, dividing by `B*1` is the same as dividing by `B`).
  * Important: the computed `loss` is a scalar `torch.tensor` (requires\_grad=True because it depends on parameters).

**Math for gradients (useful to understand backward):**

* Let $e_i = \hat{y}_i - y_i$.
* For MSE mean: $\frac{\partial L}{\partial \hat{y}_i} = \frac{2 e_i}{B}$.
* For the linear layer ( \hat{y}\_i = w x\_i + b\ ):

  * $\frac{\partial L}{\partial w} = \sum_i \frac{2 e_i}{B} x_i$ → shape `(1,10)`.
  * ( \frac{\partial L}{\partial b} = \sum\_i \frac{2 e\_i}{B}`→ shape`(1,)\`.

---

## 2) Zero gradients

```python
optimizer.zero_grad()   # clear gradients
```

* **Why:** PyTorch **accumulates** gradients into `.grad` (adds on top) by design. If you don't zero them, gradients from multiple `loss.backward()` calls will accumulate.
* `optimizer.zero_grad()` sets `.grad` to zero for all params tracked by this optimizer.
* Alternative: `model.zero_grad()` does similar; `optimizer.zero_grad(set_to_none=True)` can be slightly more memory efficient (sets grads to `None`).

**Common bug:** forgetting `zero_grad()` leads to gradients summing across batches, which will cause wrong updates (usually exploding gradients).

---

## 3) Backward pass (autograd)

```python
loss.backward()         # compute gradients
```

* Builds/uses the computational graph created during the forward pass and computes gradients (reverse-mode autodiff).
* After this call:

  * Each parameter `p` (e.g., `model.weight`, `model.bias`) has `.grad` populated with `∂loss/∂p`.
  * `.grad` shape matches the parameter shape: `weight.grad` → `(1,10)`, `bias.grad` → `(1,)`.
* These gradients are **accumulated** (added) to `.grad` if they were already non-zero (hence zeroing beforehand).

**Edge cases & tips:**

* If you call `loss.backward(retain_graph=True)`, PyTorch will keep the computational graph (useful for multiple backward passes on same graph, rarely needed in standard training).
* Do not perform in-place operations on tensors that require grad in a way that breaks gradient computation.

---

## 4) Optimizer step — update parameters

```python
optimizer.step()        # adjust weights
```

* For `optim.SGD` (no momentum), the update is:

  $$
  p \leftarrow p - \text{lr} \times p.grad
  $$

  done in-place on each parameter tensor `p`.
* After `optimizer.step()`, parameters have been updated for the next iteration.

**Notes:**

* If using momentum (`optim.SGD(..., momentum=0.9)`), `optimizer` keeps internal `velocity` buffers and uses them to modify updates (smooth/accelerate).
* If using `weight_decay`, an L2 penalty is effectively added to `p.grad` before the update.
* Always call `optimizer.step()` **after** `loss.backward()` (so gradients exist).

---

## Logging / print

```python
print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")
```

* `loss` is a 0-dim tensor; `.item()` extracts a Python float (useful for logging or storing).
* Note: this prints the **loss from the last batch of the epoch**, not the average epoch loss. If you want epoch-level logging, accumulate batch losses and divide by number of batches.

---

## Extra details & best practices

* **Train vs Eval modes**

  * `model.train()` enables behaviors like dropout and batchnorm running stats updates.
  * `model.eval()` disables dropout and uses running statistics for batchnorm; also you should wrap evaluation in `with torch.no_grad():` to avoid building autograd graphs and to save memory.
* **Device management**

  * For GPU training, move tensors & model: `model.to(device)`, `inputs = inputs.to(device)`, etc.
  * Forgetting to move both model and data to same device leads to runtime errors.
* **Gradient clipping**

  * For unstable training: `torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)`
* **Schedulers**

  * Adjust learning rate over time with `torch.optim.lr_scheduler` (e.g., `StepLR`, `ReduceLROnPlateau`).
* **DataLoader**

  * For real projects use `torch.utils.data.DataLoader` for shuffling, batching, parallel data loading, and reproducible iteration.
* **Mixed precision**

  * Use `torch.cuda.amp` for speed/memory benefits on GPUs.
* **Monitoring**

  * Log training and validation loss, accuracy, and possibly gradients / weight norms to detect problems.

---

## Common bugs you can now check for

* Forgetting `optimizer.zero_grad()` → gradients accumulate and updates are wrong.
* Mismatched shapes between `outputs` and `targets` → loss errors or broadcasting bugs.
* Using `torch.no_grad()` during training (accidentally) → `loss.backward()` will fail because no grad graph was built.
* Incorrect `reduction` behavior: if `MSELoss(reduction='sum')` then gradient scale differs (you must account for that).
* In-place operations on tensors needed for grad → can break autograd.
* Not switching `model.eval()` during validation → dropout/batchnorm behave differently.

---

## Quick checklist before training starts

* [ ] `model` and data on same device (CPU/GPU).
* [ ] Correct `dtype` (usually `float32`).
* [ ] Loss reduction understood (`mean` vs `sum`).
* [ ] `optimizer` initialized with `model.parameters()`.
* [ ] `optimizer.zero_grad()` called each iteration before `loss.backward()`.
* [ ] Call `optimizer.step()` after `loss.backward()`.
* [ ] Use `model.train()` for training and `model.eval()` + `torch.no_grad()` for validation/testing.
