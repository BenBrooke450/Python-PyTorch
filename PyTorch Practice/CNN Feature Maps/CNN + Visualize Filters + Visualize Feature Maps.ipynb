{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn"
   ],
   "id": "a8334f17efb1d88a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)  # 16 filters\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(16*56*56, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.pool(nn.ReLU()(self.conv1(x)))  # Save conv1 output\n",
    "        x2 = self.pool(nn.ReLU()(self.conv2(x1))) # Save conv2 output\n",
    "        x_flat = x2.view(-1, 16*56*56)\n",
    "        out = self.fc1(x_flat)\n",
    "        return out, x1, x2"
   ],
   "id": "eba673029e2f189",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "id": "3508077679628649",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "\n",
    "img_folder = \"/Users/benjaminbrooke/.cache/kagglehub/datasets/aryashah2k/breast-ultrasound-images-dataset/versions/1/Dataset_BUSI_with_GT/Train_data/benign\"\n",
    "\n",
    "random_choice = random.choice(os.listdir(img_folder))\n",
    "\n",
    "img =  os.path.join(img_folder,random_choice)\n",
    "\n",
    "img = Image.open(img)"
   ],
   "id": "bf2e7db32d6ee912",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "Train_dataset = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "Test_dataset = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    \"/Users/benjaminbrooke/.cache/kagglehub/datasets/aryashah2k/breast-ultrasound-images-dataset/versions/1/Dataset_BUSI_with_GT/Train_data\",\n",
    "    Train_dataset)\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    \"/Users/benjaminbrooke/.cache/kagglehub/datasets/aryashah2k/breast-ultrasound-images-dataset/versions/1/Dataset_BUSI_with_GT/Test_data\",\n",
    "    Test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ],
   "id": "baa9956de545fe61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_loader.batch_size",
   "id": "78e22ddf4cb19841",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_dataset.classes",
   "id": "d8c2df661d9817a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_kernels(layer, ncols=4):\n",
    "    kernels = layer.weight.data.clone()\n",
    "    n_filters = kernels.shape[0]\n",
    "\n",
    "    nrows = (n_filters + ncols - 1) // ncols\n",
    "    plt.figure(figsize=(ncols*2, nrows*2))\n",
    "\n",
    "    for i in range(n_filters):\n",
    "        k = kernels[i]\n",
    "        # Normalize to 0-1\n",
    "        k = (k - k.min()) / (k.max() - k.min())\n",
    "        # Convert CxHxW -> HxWxC for plotting\n",
    "        k_img = k.permute(1,2,0)\n",
    "        plt.subplot(nrows, ncols, i+1)\n",
    "        plt.imshow(k_img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Kernel {i}\")\n",
    "    plt.show()\n"
   ],
   "id": "23dd489ca8484bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_image(img):\n",
    "    img = img / 2 + 0.5  # unnormalize from [-1,1] to [0,1]\n",
    "    npimg = img.numpy()\n",
    "    # C x H x W ‚Üí H x W x C\n",
    "    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    plt.imshow(npimg)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "id": "9d08b4351f799a50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_feature_maps(feature_map, ncols=4):\n",
    "    # feature_map shape: (batch_size, channels, H, W)\n",
    "    fmap = feature_map[0]  # first image in batch\n",
    "    n_maps = fmap.shape[0]\n",
    "\n",
    "    nrows = (n_maps + ncols - 1) // ncols\n",
    "    plt.figure(figsize=(ncols*2, nrows*2))\n",
    "\n",
    "    for i in range(n_maps):\n",
    "        m = fmap[i]\n",
    "        # Normalize to 0-1\n",
    "        m = (m - m.min()) / (m.max() - m.min())\n",
    "        plt.subplot(nrows, ncols, i+1)\n",
    "        plt.imshow(m.detach().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Map {i}\")\n",
    "    plt.show()\n"
   ],
   "id": "f164e24b0c0bd80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = SmallCNN()\n",
    "\n",
    "\n",
    "\n",
    "model.parameters"
   ],
   "id": "fca853c5850939d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Absolutely ‚Äî I'll walk you **step-by-step** through how a single image with shape:\n",
    "\n",
    "```\n",
    "[1, 3, 244, 244]\n",
    "```\n",
    "\n",
    "flows through your model, including **every convolution**, **ReLU**, **pooling**, **tensor sizes**, and **the exact final flatten size**.\n",
    "\n",
    "---\n",
    "\n",
    "# üîç **Your model**\n",
    "\n",
    "```python\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(16*56*56, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.pool(nn.ReLU()(self.conv1(x)))\n",
    "        x2 = self.pool(nn.ReLU()(self.conv2(x1)))\n",
    "        x_flat = x2.view(-1, 16*56*56)\n",
    "        out = self.fc1(x_flat)\n",
    "        return out, x1, x2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# üìå Start with input\n",
    "\n",
    "You feed **one image**:\n",
    "\n",
    "```\n",
    "x = [1, 3, 244, 244]\n",
    "```\n",
    "\n",
    "(batch size = 1)\n",
    "\n",
    "---\n",
    "\n",
    "# üßÆ **1. First Convolution Layer**\n",
    "\n",
    "```\n",
    "conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "```\n",
    "\n",
    "### Formula:\n",
    "\n",
    "Conv2d output size:\n",
    "\n",
    "$$\n",
    "[\n",
    "H_\\text{out} = \\frac{H + 2P - K}{S} + 1\n",
    "]\n",
    "$$\n",
    "\n",
    "* H = 244\n",
    "* K = 3\n",
    "* P = 1\n",
    "* S = 1\n",
    "\n",
    "$$\n",
    "[\n",
    "H_\\text{out} = \\frac{244 + 2(1) - 3}{1} + 1 = 244\n",
    "]\n",
    "$$\n",
    "\n",
    "### ‚úî Output after conv1:\n",
    "\n",
    "```\n",
    "[1, 8, 244, 244]\n",
    "```\n",
    "\n",
    "8 feature maps, each same size as input.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚ú¥ **2. ReLU**\n",
    "\n",
    "Shape stays the same:\n",
    "\n",
    "```\n",
    "[1, 8, 244, 244]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# üü¶ **3. MaxPool2d(2,2)**\n",
    "\n",
    "Max pooling halves height and width:\n",
    "\n",
    "$$\n",
    "[\n",
    "244 \\rightarrow 122\n",
    "]\n",
    "$$\n",
    "\n",
    "### ‚úî Output after pool:\n",
    "\n",
    "```\n",
    "x1 = [1, 8, 122, 122]\n",
    "```\n",
    "\n",
    "This is **your first feature map output**.\n",
    "\n",
    "---\n",
    "\n",
    "# üßÆ **4. Second Convolution Layer**\n",
    "\n",
    "```\n",
    "conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "```\n",
    "\n",
    "Same formula:\n",
    "\n",
    "$$\n",
    "[\n",
    "H_\\text{out} = \\frac{122 + 2(1) - 3}{1} + 1 = 122\n",
    "]\n",
    "$$\n",
    "\n",
    "### ‚úî Output after conv2:\n",
    "\n",
    "```\n",
    "[1, 16, 122, 122]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# ‚ú¥ **5. ReLU**\n",
    "\n",
    "Shape stays:\n",
    "\n",
    "```\n",
    "[1, 16, 122, 122]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# üü¶ **6. MaxPool2d(2,2)**\n",
    "\n",
    "$$\n",
    "[\n",
    "122 \\rightarrow 61\n",
    "]\n",
    "$$\n",
    "\n",
    "Pooling halves odd numbers by flooring.\n",
    "\n",
    "### ‚úî Output after pool:\n",
    "\n",
    "```\n",
    "x2 = [1, 16, 61, 61]\n",
    "```\n",
    "\n",
    "This is **your second feature map output**.\n",
    "\n",
    "---\n",
    "\n",
    "# üîç **7. Flatten**\n",
    "\n",
    "You wrote:\n",
    "\n",
    "```python\n",
    "x_flat = x2.view(-1, 16*56*56)\n",
    "```\n",
    "\n",
    "But your actual feature map is:\n",
    "\n",
    "```\n",
    "[1, 16, 61, 61]\n",
    "```\n",
    "\n",
    "Total elements per sample:\n",
    "\n",
    "$$\n",
    "[\n",
    "16 \\times 61 \\times 61 = 59536\n",
    "]\n",
    "$$\n",
    "\n",
    "Since you force it to reshape to `16*56*56 = 50176`:\n",
    "\n",
    "* 59536 √∑ 50176 ‚âà 1.19 ‚Üí ‚ö† not divisible\n",
    "* PyTorch instead produces a **wrong batch dimension**.\n",
    "\n",
    "---\n",
    "\n",
    "# üìè **8. Final output: correct size**\n",
    "\n",
    "After fixing:\n",
    "\n",
    "```\n",
    "out = [1, 3]\n",
    "```\n",
    "\n",
    "One sample ‚Üí 3 output class logits.\n",
    "\n",
    "---\n",
    "\n",
    "# üìä **Summary Table**\n",
    "\n",
    "| Step | Layer   | Input ‚Üí Output Size |\n",
    "| ---- | ------- | ------------------- |\n",
    "| 0    | Input   | `[1, 3, 244, 244]`  |\n",
    "| 1    | Conv1   | `[1, 8, 244, 244]`  |\n",
    "| 2    | ReLU    | `[1, 8, 244, 244]`  |\n",
    "| 3    | Pool    | `[1, 8, 122, 122]`  |\n",
    "| 4    | Conv2   | `[1, 16, 122, 122]` |\n",
    "| 5    | ReLU    | `[1, 16, 122, 122]` |\n",
    "| 6    | Pool    | `[1, 16, 61, 61]`   |\n",
    "| 7    | Flatten | `[1, 59536]`        |\n",
    "| 8    | FC1     | `[1, 3]`            |\n",
    "\n"
   ],
   "id": "2a2e72006d47d3dd"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100  # Keep small for testing\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs, labels\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, fmap1, fmap2 = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Visualize kernels and feature maps after first batch of each epoch\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(\"Label:\", labels[0].item())\n",
    "            plot_image(inputs[0])\n",
    "\n",
    "            print(f\"Epoch {epoch+1} Kernels conv1:\")\n",
    "            plot_kernels(model.conv1)\n",
    "\n",
    "            print(f\"Epoch {epoch+1} Feature maps conv1:\")\n",
    "            plot_feature_maps(fmap1)\n",
    "\n",
    "            print(f\"Epoch {epoch+1} Feature maps conv2:\")\n",
    "            plot_feature_maps(fmap2)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {loss.item():.4f}\")\n"
   ],
   "id": "dda90af5b1994580",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
