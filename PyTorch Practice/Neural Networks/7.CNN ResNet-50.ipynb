{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-30T19:30:23.555778Z",
     "start_time": "2025-11-30T19:30:23.547404Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "#   Bottleneck Block (ResNet-50)\n",
    "# -------------------------------\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4   # output channels expanded by 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride,padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,kernel_size=1, bias=False)\n",
    "        self.bn3   = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample  # projection shortcut (1Ã—1 conv) if needed\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity   # skip connection\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:30:23.570117Z",
     "start_time": "2025-11-30T19:30:23.562535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------\n",
    "#     ResNet-50 Architecture\n",
    "# -------------------------------\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = 64\n",
    "\n",
    "        # --- initial conv + maxpool ---\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(64)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # --- ResNet layers ---\n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        # --- classification head ---\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # Initialize weights (optional)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out',nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    # Build each stage: (1x1, 3x3, 1x1) blocks repeated L times\n",
    "    def _make_layer(self, block, out_channels, blocks, stride):\n",
    "        downsample = None\n",
    "\n",
    "        # If shape changes (channels or stride), need projection shortcut\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels,\n",
    "                          out_channels * block.expansion,\n",
    "                          kernel_size=1,\n",
    "                          stride=stride,\n",
    "                          bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)  # 3 bottlenecks\n",
    "        x = self.layer2(x)  # 4 bottlenecks\n",
    "        x = self.layer3(x)  # 6 bottlenecks\n",
    "        x = self.layer4(x)  # 3 bottlenecks\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ],
   "id": "bb73a9477b4df70c",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:30:23.588425Z",
     "start_time": "2025-11-30T19:30:23.573772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                 transforms.Resize(size=(224,224))])\n",
    "\n",
    "train_set = datasets.ImageFolder(\"/Users/benjaminbrooke/.cache/kagglehub/datasets/sriramr/apples-bananas-oranges/versions/1/original_data_set/train_data\", transform=transforms)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle = True)"
   ],
   "id": "11a3131259f15137",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:30:23.713236Z",
     "start_time": "2025-11-30T19:30:23.592222Z"
    }
   },
   "cell_type": "code",
   "source": "model_one = ResNet(Bottleneck,[1,1,1,1],num_classes=6)",
   "id": "2386d34d76fb1f50",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:30:23.726209Z",
     "start_time": "2025-11-30T19:30:23.717811Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = torch.optim.Adam(model_one.parameters(),lr=0.01)",
   "id": "d068a4fc38d9e044",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:30:23.733485Z",
     "start_time": "2025-11-30T19:30:23.730761Z"
    }
   },
   "cell_type": "code",
   "source": "loss_fn = nn.CrossEntropyLoss()",
   "id": "c0569dfedf7379dc",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:32:55.948814Z",
     "start_time": "2025-11-30T19:30:31.925678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "step = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model_one.train()\n",
    "\n",
    "    running_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\", leave=True)\n",
    "\n",
    "    for X_train, y_train in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model_one(X_train)\n",
    "\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        preds = y_pred.argmax(dim=1)\n",
    "        acc = (preds == y_train).float().mean().item()\n",
    "\n",
    "        writer.add_scalar(\"Loss/train\", loss.item(), step)\n",
    "        writer.add_scalar(\"Accuracy/train\", acc, step)\n",
    "\n",
    "        step = step + 1"
   ],
   "id": "bdfa394f2ca3132e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch [1/1]:   0%|          | 0/96 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d82a88029b90439684cbe680791586dd"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:33:49.673821Z",
     "start_time": "2025-11-30T19:33:49.655622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ],
   "id": "ef51fca50d1c5c69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 36797), started 1 day, 19:03:45 ago. (Use '!kill 36797' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "d4184ad205b811dd9a899c4ecef6e518"
     }
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2d9c0c777cdeca3d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2d9c0c777cdeca3d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
